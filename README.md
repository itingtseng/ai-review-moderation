# ðŸ¤– AI Review Moderation System  
*Automated Review Classification & Semantic Similarity Search*

---

## ðŸŒŸ Overview

This project builds an **AI-driven review moderation system** that automatically detects, explains, and retrieves similar problematic user reviews (spam, fake, or inappropriate).  
It combines **ML classification**, **semantic search (FAISS)**, and **Streamlit visualization** into one end-to-end workflow.

> ðŸ§  Designed & implemented by [I-Ting (Tiffany) Tseng](https://github.com/itingtseng)

---

## ðŸš€ Live Demo

ðŸŽ¬ **Try it here:** [ðŸ‘‰ Streamlit App](https://ai-review-moderation-l3qjzfruzteibe839gksno.streamlit.app)

- ðŸ“ Input a review â†’ get predicted **moderation reason** + confidence  
- ðŸ” Retrieve **similar cases** from FAISS vector index  
- ðŸ“Š View descriptive **insights** on review patterns and trends  

---

## ðŸ§© System Architecture

```mermaid
flowchart LR
    A[User Input] --> B[FastAPI Backend]
    B -->|Embedding| C[SentenceTransformer]
    C -->|Vector Search| D[FAISS Index]
    B -->|Classification| E[LogReg Model]
    D --> F[Similar Examples]
    E --> G[Predicted Reason + Confidence]
    F --> H[Streamlit Frontend]
    G --> H

---

## ðŸ“Š Results

| Metric | Score |
|:--|:--:|
| Accuracy | 0.87 |
| F1 | 0.83 |
| Recall @ 5 (FAISS) | 0.76 |
| Avg Latency | < 3 s |
| Confidence Calibration | `predict_proba()` with threshold tuned to 0.7 for flagging cases for human review |

---

## ðŸ“Š Insights Highlights 

This notebook (notebooks/05_insights.ipynb) generates descriptive analytics about the moderation dataset. 

| Chart | Description | 
|-------|--------------| 
| ![Class Distribution](reports/insights/class_distribution.png) | Volume by reason | 
| ![Trend](reports/insights/monthly_trend_topN.png) | Monthly trend of top 8 reasons |

---

## âœ… PM Insights

- "Spam" reviews surged 25 % MoM after promotional campaign launch.  
- 70 % of "Fake Review" cases share similar wording patterns (â€œbest everâ€, â€œhighly recommendedâ€).  
- Low-confidence (â‰¤ 0.6) predictions account for 18 % â€” ideal threshold for manual review escalation.  
- Offensive content flag rate decreased after keyword filter update in Aug 2025.

---

## ðŸ§­ Product Impact

- âœ… Reduces manual moderation effort
- âœ… Improves reviewer transparency & trust via confidence visualization
- âœ… Supports scalable AIâ€“human hybrid workflows
- âœ… Enables data-driven policy updates through trend insights

---

## ðŸ§° Tech Stack

| Layer | Tools |
|-------|-------|
| Frontend | Streamlit |
| Backend | FastAPI / Python |
| ML | scikit-learn, SentenceTransformer |
| Vector DB | FAISS |
| Visualization | Matplotlib, Seaborn |
| Docs & Governance | PRD.md Â· model_card.md Â· ethics.md |

---

## ðŸ§° Tech Stack

| Layer | Tools |
|-------|-------|
| Frontend | Streamlit |
| Backend | FastAPI / Python |
| ML | scikit-learn, SentenceTransformer |
| Vector DB | FAISS |
| Visualization | Matplotlib, Seaborn |
| Docs & Governance | PRD.md Â· model_card.md Â· ethics.md |

---

## ðŸ‘©ðŸ»â€ðŸ’» Author

**I-Ting (Tiffany) Tseng**  
Product Manager & Software Engineer  

ðŸŒ [**Live Demo**](https://ai-review-moderation-l3qjzfruzteibe839gksno.streamlit.app) | ðŸ’¼ [**LinkedIn**](https://www.linkedin.com/in/ittseng) | ðŸ’» [**GitHub**](https://github.com/itingtseng)


